---
title: "Estimating species richness from an aggregation of inventory plots"
author:
  - name: "Eric Marcon"
date: "`r format(Sys.time(), '%d %B %Y')`"
url: https://EricMarcon.github.io/Chao2-Aggregated/
github-repo: EricMarcon/Chao2-Aggregated
# Language
lang: en-US
# Bibliography
bibliography: references.bib
biblio-style: chicago
# LaTeX
preamble: >
  \hyphenation{bio-di-ver-si-ty sap-lings}
# Print table of contents in PDFs?
pdftoc: false
# If true, choose its depth
toc-depth: 3
# Do not modify
always_allow_html: yes
output:
  rmdformats::downcute:
    use_bookdown: yes
    lightbox: yes
---

```{r DoNotModify, include=FALSE}
### Utilities. Do not modify.
# Installation of packages if necessary
InstallPackages <- function(Packages) {
  InstallPackage <- function(Package) {
    if (!Package %in% installed.packages()[, 1]) {
      install.packages(Package, repos="https://cran.rstudio.com/")
    }
  }
  invisible(sapply(Packages, InstallPackage))
}

# Basic packages
InstallPackages(c("bookdown", "formatR", "kableExtra", "ragg"))

# kableExtra must be loaded 
if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
  # Word output (https://stackoverflow.com/questions/35144130/in-knitr-how-can-i-test-for-if-the-output-will-be-pdf-or-word)
  # Do not use autoformat (https://github.com/haozhu233/kableExtra/issues/308)
  options(kableExtra.auto_format = FALSE)
}
library("kableExtra")

# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r Options, include=FALSE}
### Customized options for this document
# Add necessary packages here
Packages <- c("tidyverse", "remotes", "spatstat")
# Install them
InstallPackages(Packages)

# From GitHub
remotes::install_github("EricMarcon/SpatDiv")

# knitr options
knitr::opts_chunk$set(
  cache = TRUE,   # Cache chunk results
  echo = TRUE,     # Show/Hide R chunks
  warning = FALSE, # Show/Hide warnings
  message = FALSE, # Show/Hide messages
  # Figure alignment and size
  fig.align = 'center', out.width = '80%',
  # Graphic devices (ragg_png is better than standard png)
  dev = c("ragg_png", "pdf"),
  # Code chunk format
  tidy = TRUE, tidy.opts = list(blank=FALSE, width.cutoff=50),
  size = "scriptsize", knitr.graphics.auto_pdf = TRUE
  )
options(width = 50)

# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(panel.background=element_rect(fill="transparent", colour=NA),
             plot.background=element_rect(fill="transparent", colour=NA))
knitr::opts_chunk$set(dev.args=list(bg="transparent"))

# Random seed
set.seed(973)
```

# Rationale

The Chao2 estimator [@Chao1987] can be used to estimate the richness of a community from occurrence data in sampling plots.

It has been applied by @CazzollaGatti2022 to abundance data of small sample plots aggregated into occurrence data on a grid.
The question addressed here is the relationship between the aggregation level and the resulting estimation.

The estimation actually does not depend on the aggregation level.

# Data

A large, spatialized community is simulated by package *SpatDiv*.
The community is log-normal.
Spatially, tree species are clustered according to a Thomas process.

Parameters are:

- the size of the square window of the simulation, including the name of units,
- the number of trees per unit area,
- the number of species, 
- the parameters of aggregation: the standard deviation of the displacements of points around the cluster centers (`thomas_scale`) and the average number of trees per cluster (`thomas_mu`).

The simulation may take time and memory over 100,000 trees.

```{r}
library("SpatDiv")
window_size <- 20000
unit_name <- c("meter", "meters")
trees_n_per_area <- 500/10000
species_n <- 500
thomas_scale <- window_size/10
thomas_mu <- 100
```

The community is simulated:

```{r}
library("spatstat")
rSpCommunity(n = 1, 
             size = window_size^2 * trees_n_per_area, 
             S = species_n, 
             Spatial = "Thomas", scale = thomas_scale, mu = thomas_mu,
             win = square(r=window_size, unitname=unit_name)
             ) -> spCommunity
# Number of trees
spCommunity$n
```

Square, random inventory plots are simulated in the community.

Their parameters are:
- their size,
- their number.

```{r}
# Plot side length
plots_side <- 30
# Number of plots
plots_n <- 50
```

Random coordinates are drawn:

```{r}
# Draw random plots
X_0 <- runif(plots_n, max = window_size)
Y_0 <- runif(plots_n, max = window_size)
# Push the plots into the window
X_min <- pmin(X_0, window_size-plots_side)
X_max <- pmin(X_0 + plots_side, window_size)
Y_min <- pmin(Y_0, window_size-plots_side)
Y_max <- pmin(Y_0 + plots_side, window_size)
# List of windows
plots_windows <- solapply(seq_along(X_0), function(i) 
  owin(xrange=c(X_min[i], X_max[i]), yrange=c(Y_min[i], Y_max[i]),
       unitname=unit_name))
# Coordinates of the plots in a dataframe
plots_coords <- data.frame(Plot=seq_len(plots_n), X=X_min, Y=Y_min)
```

The plots are mapped:

```{r}
# spatstat
# plot(intersect.owin(spCommunity$window, union.owin(plots_windows)))

# ggplot
window_all <- data.frame(xmin = c(spCommunity$window$xrange[1], X_min),
                         xmax = c(spCommunity$window$xrange[2], X_max),
                         ymin = c(spCommunity$window$yrange[1], Y_min),
                         ymax = c(spCommunity$window$yrange[2], Y_max)
                         )
library("ggplot2")
gg_plots <- ggplot() +
  geom_rect(data = window_all, mapping = aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), color="black", fill="transparent") +
  coord_fixed()
print(gg_plots)
```
The sampling intensity is `r format(plots_n * plots_side^2 / window_size^2 * 100, digits=3)`% of the total area.

Any plot can be mapped with its content.
The first one is:

```{r}
plot_to_draw <- plots_windows[[1]]
library("dbmss")
autoplot(spCommunity[plot_to_draw])
```



# Inventory

The inventory of a plot is made by the `plot_trees()` function which return a boolean vector for all the trees of the community.
Its value is `TRUE` when a tree is in the plot.

```{r}
plot_trees <- function(spCommunity, plots_side, x_0, y_0) {
  # Trees in the plot
  is_in <- (spCommunity$x >= x_0) & (spCommunity$x <= x_0 + plots_side) &
      (spCommunity$y >= y_0) & (spCommunity$y <= y_0 + plots_side)
  return(is_in)
}
```


The inventory is simulated: the trees inside each plot are listed and a abundance by plot dataframe is produced.

```{r}
# Initialize a dataframe with factors
plots_inventory <- data.frame()
# Inventory
for (i in seq_len(plots_n)) {
  plot_inventory <- data.frame(
    Plot = i, 
    Tree = spCommunity$marks$PointType[plot_trees(spCommunity, plots_side, X_min[i], Y_min[i])]
    )
  plots_inventory <- rbind(plots_inventory, plot_inventory)
}

# Transform the inventory into an abundance table
library("tidyverse")
plots_inventory %>%
  group_by(Plot, Tree) %>%
  summarise(Abundance = n()) %>%
  pivot_wider(names_from = Tree, values_from = Abundance, values_fill=0) ->
  plots_abundances
```


# Aggregation

plots are grouped in the cells of a grid by the function `group_plots()`.
It returns a three-column dataframe with the plot names and the *x* and *y* coordinates of the left lower corner of the cell of the grid each plot belongs to.

```{r}
# Group plots in a grid
group_plots <- function(plots, grid_x, grid_y) {
  grid_xy <- matrix(0, nrow=nrow(plots), ncol=2)
  for (row in seq_len(nrow(plots))) {
    grid_xy[row, 1] <- grid_x[max(which(plots$X[row] > grid_x))]
    grid_xy[row, 2] <- grid_y[max(which(plots$Y[row] > grid_y))]
  }
  colnames(grid_xy) <- c("x_grid", "y_grid")
  return(grid_xy)
}
```


```{r}
abundance_gridded <- function(abundances, plots, grid_size, x_min=0, x_max=1, y_min=0, y_max=1) {
  
  grid_x <- seq(x_min, x_max, by=grid_size)
  grid_y <- seq(y_min, y_max, by=grid_size)
  plots_gridded <- cbind(plots["Plot"], group_plots(plots, grid_x, grid_y))

  abundances %>%
    inner_join(plots_gridded) %>%
    select(-Plot) %>%
    group_by(x_grid, y_grid) %>%
    summarise_all(sum) ->
    abundances_aggregated
  
  return(abundances_aggregated)
}
```

The `richness_gridded()` function returns the estimation of richness by the Chao2 estimator after aggregating the plots of each cell of the grid.

```{r}
richness_gridded <- function(abundances, plots, grid_size, x_min=0, x_max=1, y_min=0, y_max=1) {

  abundances_aggregated <- abundance_gridded(abundances, plots, grid_size, x_min, x_max, y_min, y_max)
  occurences <- apply(abundances_aggregated[, -(1:3)] , 2, function(x) sum(x>0))

  n <- nrow(abundances_aggregated)
  s_obs <- sum(occurences > 0)
  s_1 <- sum(occurences == 1)
  s_2 <- sum(occurences == 2)
  s_chao2 <- ifelse(s_2 > 0,
                    s_obs + (n-1) * s_1^2 / 2 / n / s_2, 
                    s_obs + (n-1) * s_1 * (s_1 -1) / 2 / n 
                    )
  return(s_chao2)
}
```

The estimation of the number of species with a 4-cell grid is:

```{r}
# Example
richness_gridded(plots_abundances,
                 plots_coords,
                 grid_size = window_size/2,
                 x_max = window_size, y_max = window_size)
```

The sensitivity to the grid size is evaluated by dividing it by 2 several times (from 1/2 to 1/32 of the community size).

```{r}
sapply(1:5, function(n) richness_gridded(plots_abundances,
                                         plots_coords,
                                         grid_size = window_size/ 2^n,
                                         x_max = window_size, 
                                         y_max = window_size)
       )
```

The estimation is very stable.

A grid size equal to 1/8th of the window (64 cells) is shown here:

```{r}
grid_interval <- window_size/ 2^3
grid_seq <- seq(grid_interval, window_size * .9999, by=grid_interval)
gg_plots +
  geom_hline(yintercept = grid_seq, col="green") +
  geom_vline(xintercept = grid_seq, col="green")
```

The estimation of richness could be made directly from the abundance data:

```{r}
Richness(colSums(plots_abundances[, -1]))
```


# Turing's relation

## Estimating the number of singletons

Turing's relation is used to derived the number of singletons $s_1$ from $s_2$, $s_3$ and $s_4$ after @Chiu2016.

The `turing()` function estimates that number of singletons to compare it to the observed one in simulated inventories.

```{r}
turing <- function(distribution, Cazzola2022=FALSE, verbose = TRUE) {
  n <- sum(distribution)
  s_1 <- sum(distribution == 1)
  if (verbose) cat("Actual number of singletons:", s_1, "\n")
  s_2 <- sum(distribution == 2)
  s_3 <- sum(distribution == 3)
  s_4 <- sum(distribution == 4)
  # Chiu at al. 2016 : s_1_hat <- (4 *s_2^2 /3 /s_3 - 2 * s_2 * s_3 /4 /s_4)
  # Keep n in Chiu at al. 2016
  s_1_hat <- 4 * (n-2) *s_2^2 /3 /(n-1) /s_3 - (n-3) *s_2 * s_3 /2 /(n-1) /s_4
  # Cazzola 2022
  if (Cazzola2022)
    s_1_hat <- (n-1) /n * 2 *s_2 * (5 *s_2 /6 /s_3 - s_3 /4 /s_4)
  if (verbose) cat("Expected number of singletons:", s_1_hat, "\n")
  return(invisible(s_1_hat))
}
```

The formula in @CazzollaGatti2022 differs from that of @Chiu2016.
It is 
$$\hat{s_1}=\frac{(n-1)}{n}\frac{2s_2^2}{3s_3} + \frac{(n-1)}{n} 2s_2 \left(\frac{s_2}{2s_3}-\frac{s_3}{4s_4}\right)$$
but the original equation is [eq. 5 of @Chiu2016 rederived without assuming $n$ is large]:
$$\hat{s_1}=\frac{(n-2)}{n-1}\frac{2s_2^2}{3s_3} + \frac{(n-2)}{n-1} 2s_2 \left(\frac{s_2}{3s_3}-\frac{s_3}{4s_4}\right).$$
The denominator of the first term of the second-to-last fraction is $3s_3$, not $2s_3$.

The estimation differs quite much, e.g. in a log-normal community:
```{r}
# Single community
community_lnorm <- rCommunity(1, size = 1000)
# Original equation
turing(community_lnorm, Cazzola2022 = FALSE)
# 3 instead of 2
turing(community_lnorm, Cazzola2022 = TRUE)
```

In both cases, the number of estimated singletons is far from the observed value.

Applied to the simulated community the estimation is sometimes correct but sometimes not, depending on the simulation:

```{r}
# Abundances
turing(colSums(plots_abundances[, -1]))

# Aggregated data, 64 cells
abundances_aggregated <- abundance_gridded(plots_abundances,
                                           plots_coords,
                                           grid_size = window_size/ 2^3,
                                           x_max = window_size,
                                           y_max = window_size)
occurences <- apply(abundances_aggregated[, -(1:3)] , 2, function(x) sum(x>0))
turing(occurences)
```

## Empirical validation

A simulation of log-normal communities shows poor empirical relations, both on simulated, small communities or on samples of a large community.

```{r}
# Small communities
simln <- rCommunity(1000, size=plots_side^2*plots_n*trees_n_per_area, Distribution = "lnorm", S=species_n)
Singletons <- apply(simln$Nsi, 2, function(distribution) sum(distribution == 1))
Estimated <- apply(simln$Nsi, 2, turing, verbose=FALSE)
plot(x=Singletons, y=Estimated)
abline(a=0, b=1, col="red")
summary(lm(Estimated ~ Singletons))

# Large community
simln <- rCommunity(1, size=1E6, Distribution = "lnorm", S=species_n)
# Samples
samples <- rmultinom(1000, size = plots_side^2*plots_n*trees_n_per_area, prob = as.ProbaVector(simln))
Singletons <- apply(samples, 2, function(distribution) sum(distribution == 1))
Estimated <- apply(samples, 2, turing, verbose=FALSE)
plot(Estimated ~ Singletons)
abline(a=0, b=1, col="red")
summary(lm(Estimated ~ Singletons))
```

The estimation of $\alpha_r$ with Turing's formula is not better.

```{r}
# Turing's formula.
alpha_r <- function(distribution, sample, r) {
  f_r <- sum(sample == r)
  f_rplus1 <- sum(sample == r+1)
  n <- sum(sample)
  alpha_r_sim <- c(
    Actual = mean(as.ProbaVector(distribution)[sample == r]), 
    Turing = (r+1) * f_rplus1 / ((n-r) * f_r + (r+1) * f_rplus1)
  )
  return(alpha_r_sim)
  # Return a vector: actual and estimated alpha_r
}

```

A large community is simulated and many samples in it.

```{r}
# Large community
simln <- rCommunity(1, size=1E6, Distribution = "lnorm", S=species_n)
# Many samples
samples <- rmultinom(1000, size=1000, simln)
```

The actual and estimated values of $\alpha_r$ are calculated:
```{r}
# Plot actual vs estimated alpha_r
compare_alpha_r <- function(distribution, sample, r) {
  alpha_rsim <- t(apply(samples, 2, function(sample) alpha_r(distribution, sample, r)))
  plot(alpha_rsim, main=paste("r=", r))
  abline(a=0, b=1, col="red")
}

sapply(1:3, function(r) compare_alpha_r(simln, sample, r))
```

## Cause for the poor predictions

This is not due to the approximation in the derivation of the improved Turing formula [@Chiu2014a, eq. 7a]: 
```{r}
# Evaluate Chiu at al. 2014 approximation
odd_approximation <- function(distribution, sample, r) {
  distribution_p <- as.ProbaVector(distribution)
  p_r <- distribution_p[sample == r]
  odd_r_sum <- sum(p_r/(1-p_r))
  odd_r_mean <- mean(p_r)/mean(1-p_r) * sum(sample == r)
  return(c(odd_r_sum, odd_r_mean))
}

# Large community
simln <- rCommunity(1, size=1E6, Distribution = "lnorm", S=species_n)
sample <- rmultinom(1, size=1000, simln)

# Approximation
odd_approximation(simln, sample, 1)
odd_approximation(simln, sample, 2)
odd_approximation(simln, sample, 3)
odd_approximation(simln, sample, 4)
```

## Appropriate application

Turing's relation does not allow to predict the observed number of singletons of a specific sample.
It is made to estimate the expected number of singletons.
The following test compares the mean estimation to the mean number of observed singletons over 1000 simulations of samples of increasing size in a large community.

```{r}
estimate_f1 <- function(sample_size) {
  # Large community
  simln <- rCommunity(1, size=1E6, Distribution = "lnorm", S=300)
  # Many samples
  samples <- rmultinom(1000, size=sample_size, simln)
  # Actual and estimated number of singletons
  Singletons <- mean(apply(samples, 2, function(distribution) sum(distribution == 1)))
  Estimated <- mean(apply(samples, 2, turing, verbose=FALSE))
  return(c(Singletons, Estimated))
}

f1_estimation <- sapply(seq(500, 5000, by=500), estimate_f1)
plot(t(f1_estimation), xlab = "Mean actual number of singletons", ylab = "mean estimated number of singletons")
abline(a=0, b=1, col="red")
```

The larger the samples (from 500 to 5000 individuals in a 300-species community), the less singletons.
The estimation is quite good on average.


## Application to the data

The `richness_gridded()` function is modified to use the number of singletons derived by Turing's relation rather than the observed data.
The argument `turing_f1` is added for that purpose.

```{r}
richness_gridded <- function(
    abundances, 
    plots, 
    grid_size, 
    x_min=0, 
    x_max=1, 
    y_min=0, 
    y_max=1,
    turing_f1 = FALSE) {

  abundances_aggregated <- abundance_gridded(
    abundances, plots, grid_size, x_min, x_max, y_min, y_max
  )
  occurences <- apply(abundances_aggregated[, -(1:3)] , 2, function(x) sum(x>0))

  n <- nrow(abundances_aggregated)
  s_obs <- sum(occurences > 0)
  s_2 <- sum(occurences == 2)
  s_3 <- sum(occurences == 3)
  s_4 <- sum(occurences == 4)
  if (turing_f1) {
    s_1 <- 4 * (n - 2) * s_2 ^ 2 / 3 / (n - 1) / s_3 - 
      (n - 3) * s_2 * s_3 / 2 / (n - 1) / s_4
  } else {
    s_1 <- sum(occurences == 1)
  }
  s_chao2 <- ifelse(
    s_2 > 0,
    s_obs + (n - 1) * s_1 ^ 2 / 2 / n / s_2, 
    s_obs + (n - 1) * s_1 * (s_1 - 1) / 2 / n 
  )
  return(s_chao2)
}
```

The estimation of the number of species with a 4-cell grid is:

```{r}
# Example
richness_gridded(plots_abundances,
                 plots_coords,
                 grid_size = window_size/2,
                 x_max = window_size, y_max = window_size,
                 turing_f1 = TRUE)
```
The sensitivity to the grid size is evaluated by dividing it by 2 several times (from 1/2 to 1/32 of the community size).

```{r}
sapply(1:5, function(n) richness_gridded(plots_abundances,
                                         plots_coords,
                                         grid_size = window_size/ 2^n,
                                         x_max = window_size, 
                                         y_max = window_size,
                                         turing_f1 = TRUE)
       )
```

These values are to be compared with those obtained above.


`r if (!knitr:::is_latex_output()) '# References {-}'`
